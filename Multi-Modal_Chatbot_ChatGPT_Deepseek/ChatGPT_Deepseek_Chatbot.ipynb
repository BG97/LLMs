{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45f94b0-1a7e-4532-9b12-957d36287536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bf5e39-2b4d-4e39-9648-8ad2817c7bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-_u\n",
      "Deepseek API Key exists and begins sk-2eb17e5\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:10]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"Deepseek API Key exists and begins {deepseek_api_key[:10]}\")\n",
    "else:\n",
    "    print(\"Deepseek API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6660c6aa-215a-4e24-b73b-b965f44e5544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Deepseek\n",
    "openai = OpenAI()\n",
    "\n",
    "deepseek_via_openai_client = OpenAI(\n",
    "    api_key=deepseek_api_key, \n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd99e59d-a0fe-40b2-ada0-fe6c0527e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an Data Scientist that is great at answering interview questions\"\n",
    "user_prompt = \"Tell me what is artificial intelligence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e04f58e5-f1fe-47ef-afff-acab74e05fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b552f8c2-b435-4d7a-b9ef-f3f88a6a5c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is a branch of computer science that focuses on the development of machines and systems that can perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. AI technologies aim to simulate cognitive functions like learning, reasoning, problem-solving, perception, and language understanding. These technologies include machine learning, neural networks, natural language processing, and computer vision. AI systems can analyze large amounts of data, recognize patterns, make predictions, and solve complex problems with varying degrees of autonomy.\n"
     ]
    }
   ],
   "source": [
    "# GPT-3.5-Turbo\n",
    "\n",
    "completion = openai.chat.completions.create(model='gpt-3.5-turbo', messages=prompts)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba54ec3b-3290-4745-b090-e42640d7bfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are designed to think and act like humans. This encompasses a variety of capabilities including learning, reasoning, problem-solving, perception, language understanding, and decision-making.\n",
      "\n",
      "There are several key components of AI:\n",
      "\n",
      "1. **Machine Learning (ML)**: A subset of AI that involves training algorithms on data so they can learn patterns and make decisions without being explicitly programmed for each task. It includes supervised, unsupervised, and reinforcement learning.\n",
      "\n",
      "2. **Natural Language Processing (NLP)**: The ability of machines to understand and interpret human language, enabling applications like chatbots, language translation, and sentiment analysis.\n",
      "\n",
      "3. **Computer Vision**: This area focuses on enabling machines to interpret and understand visual information from the world, such as recognizing objects, faces, or even actions in videos.\n",
      "\n",
      "4. **Robotics**: The integration of AI with robotics involves creating machines that can perform tasks autonomously or semi-autonomously, often in real-time environments.\n",
      "\n",
      "5. **Expert Systems**: These are AI systems that use a knowledge base of human expertise to solve specific problems, often in fields like medicine or engineering.\n",
      "\n",
      "AI can be categorized into two main types:\n",
      "\n",
      "- **Narrow AI**: Also known as weak AI, this type is designed to perform a narrow task, such as facial recognition or internet searches. Most AI applications today fall into this category.\n",
      "\n",
      "- **General AI**: Also known as strong AI, this type would have the ability to understand, learn, and apply intelligence broadly, similar to a human. As of now, general AI remains a theoretical concept and has not been achieved.\n",
      "\n",
      "Overall, AI has the potential to transform various industries by improving efficiencies, enabling new capabilities, and providing insights from large datasets. However, it also raises ethical considerations regarding privacy, bias, and job displacement that need to be addressed as the technology continues to evolve.\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o-mini\n",
    "# Temperature setting controls creativity\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=prompts,\n",
    "    temperature=0.7\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0fdc3d4-b549-4bea-acf4-e6e44f1955f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think, learn, and make decisions like humans. These machines are designed to perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation.\n",
      "\n",
      "AI can be categorized into two main types:\n",
      "\n",
      "1. **Narrow AI (Weak AI):** This type of AI is designed to perform a specific task. Examples include voice assistants like Siri or Alexa, recommendation systems on Netflix or Amazon, and image recognition software. Narrow AI operates within a limited context and does not possess general intelligence.\n",
      "\n",
      "2. **General AI (Strong AI):** This is a more advanced form of AI that possesses the ability to understand, learn, and apply knowledge across a wide range of tasks, much like a human being. General AI can perform any intellectual task that a human can do. However, this type of AI is still largely theoretical and has not been fully realized.\n",
      "\n",
      "### Key Components of AI:\n",
      "- **Machine Learning (ML):** A subset of AI that involves training algorithms to learn from and make predictions or decisions based on data. ML models improve their performance as they are exposed to more data over time.\n",
      "  \n",
      "- **Deep Learning:** A specialized form of ML that uses neural networks with many layers (hence \"deep\") to analyze various factors of data. It is particularly effective in tasks like image and speech recognition.\n",
      "\n",
      "- **Natural Language Processing (NLP):** This involves the interaction between computers and humans using natural language. NLP enables machines to understand, interpret, and generate human language.\n",
      "\n",
      "- **Computer Vision:** This field enables machines to interpret and make decisions based on visual input from the world, such as images or videos.\n",
      "\n",
      "- **Robotics:** AI is often integrated into robots to enable them to perform tasks autonomously or semi-autonomously.\n",
      "\n",
      "### Applications of AI:\n",
      "- **Healthcare:** AI is used for diagnostics, personalized medicine, and drug discovery.\n",
      "- **Finance:** AI helps in fraud detection, algorithmic trading, and risk management.\n",
      "- **Transportation:** Autonomous vehicles and traffic management systems rely heavily on AI.\n",
      "- **Retail:** AI powers recommendation engines, inventory management, and customer service chatbots.\n",
      "- **Manufacturing:** AI optimizes supply chains, predictive maintenance, and quality control.\n",
      "\n",
      "### Ethical Considerations:\n",
      "- **Bias and Fairness:** AI systems can inadvertently perpetuate biases present in the data they are trained on.\n",
      "- **Privacy:** The use of AI in surveillance and data analysis raises concerns about individual privacy.\n",
      "- **Job Displacement:** Automation powered by AI could lead to job losses in certain sectors.\n",
      "- **Accountability:** Determining responsibility for decisions made by AI systems can be challenging.\n",
      "\n",
      "AI is a rapidly evolving field with the potential to revolutionize many aspects of society, but it also comes with significant ethical and practical challenges that need to be addressed.\n"
     ]
    }
   ],
   "source": [
    "# Deepseek\n",
    "completion = deepseek_via_openai_client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=prompts,\n",
    "    temperature=0.7,\n",
    "    stream=False\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cb5beb0-d92a-4127-ab49-ecaa27c01431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Alright, let's tackle this intriguing question: **\"How many words are there in your answer to this prompt?\"** At first glance, it seems straightforward, but upon closer inspection, it's a bit of a paradox. Let's break it down step by step to understand and find a solution.\n",
       "\n",
       "### Understanding the Question\n",
       "\n",
       "The question is essentially asking for the word count of the answer itself. This creates a self-referential loop because the length of the answer depends on the content of the answer, which includes the word count.\n",
       "\n",
       "### Breaking Down the Problem\n",
       "\n",
       "1. **Self-Reference**: The answer's word count is part of the answer. If I state the word count, it affects the total number of words.\n",
       "   \n",
       "2. **Infinite Loop**: If I try to count the words as I write, each addition or change in the answer alters the total word count, making it impossible to reach a fixed number.\n",
       "\n",
       "3. **Practical Constraints**: In reality, there must be a way to provide an answer without getting stuck in an infinite loop.\n",
       "\n",
       "### Exploring Possible Solutions\n",
       "\n",
       "Let's consider a few approaches to resolve this:\n",
       "\n",
       "#### 1. Fixed-Length Answer\n",
       "\n",
       "If I decide to write an answer of a specific length, say 100 words, then the word count would be 100. However, the moment I state that, the total word count changes, potentially making it more or less than 100.\n",
       "\n",
       "**Issue**: This approach doesn't resolve the self-reference problem.\n",
       "\n",
       "#### 2. Approximate Word Count\n",
       "\n",
       "Instead of an exact number, I could provide an approximate word count. For example, \"This answer contains approximately 150 words.\"\n",
       "\n",
       "**Pros**:\n",
       "- Avoids the precision that leads to the infinite loop.\n",
       "- Gives a rough idea without exactness.\n",
       "\n",
       "**Cons**:\n",
       "- The approximation itself might not be accurate as the answer evolves.\n",
       "\n",
       "#### 3. Recursive Definition\n",
       "\n",
       "Define the word count in a way that accounts for its own inclusion. For instance, \"This answer contains X words,\" where X is calculated considering the entire answer.\n",
       "\n",
       "**Challenge**:\n",
       "- Calculating X requires knowing X, leading back to the original problem.\n",
       "\n",
       "#### 4. External Reference\n",
       "\n",
       "Refer to an external standard or tool to count the words after the answer is complete.\n",
       "\n",
       "**Pros**:\n",
       "- Removes the self-reference issue by using an independent method.\n",
       "\n",
       "**Cons**:\n",
       "- Relies on an external factor, which might not always be feasible or accurate.\n",
       "\n",
       "### Evaluating the Best Approach\n",
       "\n",
       "Considering the above, the **Approximate Word Count** seems the most practical. It acknowledges the self-referential nature without getting bogged down by exactness.\n",
       "\n",
       "### Implementing the Approximate Word Count\n",
       "\n",
       "Let's proceed by writing the answer and then estimating the word count.\n",
       "\n",
       "---\n",
       "\n",
       "**Answer:**\n",
       "\n",
       "The question asks for the number of words in this very answer, creating a self-referential challenge. To address this, we can provide an approximate word count. This approach avoids the infinite loop caused by exact self-reference. By estimating, we acknowledge that the word count is roughly around 150 words, give or take a few. This method balances providing useful information without getting entangled in the paradox of exact self-measurement.\n",
       "\n",
       "---\n",
       "\n",
       "**Estimated Word Count**: Approximately 150 words.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "While the question presents a fascinating paradox, the most practical solution is to provide an approximate word count. This way, we offer a useful response without falling into the trap of infinite self-reference.\n",
       "\n",
       "**Final Answer**: This answer contains approximately 150 words."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 509\n"
     ]
    }
   ],
   "source": [
    "# Using DeepSeek Chat with a harder question! And streaming results\n",
    "challenge = [{\"role\": \"system\", \"content\": \"You are an Data Scientist that is great at answering interview questions\"},\n",
    "             {\"role\": \"user\", \"content\": \"How many words are there in your answer to this prompt\"}]\n",
    "\n",
    "stream = deepseek_via_openai_client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=challenge,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)\n",
    "\n",
    "print(\"Number of words:\", len(reply.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2b796c3-f60a-4d52-90c1-a7d9a66d4126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Alright, let's tackle this intriguing question: **\"How many words are there in your answer to this prompt?\"** At first glance, it seems straightforward, but upon closer inspection, it's a bit of a paradox. Let's break it down step by step to understand and find a meaningful answer.\n",
       "\n",
       "### Understanding the Question\n",
       "\n",
       "The question is asking for the word count of the very answer that's being provided. This creates a self-referential loop because the length of the answer depends on the content of the answer itself. It's similar to the classic \"This statement is false\" paradox.\n",
       "\n",
       "### Breaking Down the Problem\n",
       "\n",
       "1. **Self-Reference**: The answer's word count is contingent upon the words used in the answer. If I say, \"This answer contains X words,\" then the value of X must accurately reflect the total number of words, including that statement.\n",
       "\n",
       "2. **Dynamic Nature**: As I add more words to explain the problem, the total word count increases, which in turn affects the accuracy of any previously stated word count.\n",
       "\n",
       "3. **Potential Infinite Loop**: Attempting to provide an exact word count within the answer could lead to an infinite loop of adjustments, as each addition or subtraction of words changes the total count.\n",
       "\n",
       "### Exploring Possible Solutions\n",
       "\n",
       "Given the self-referential nature of the question, let's explore potential ways to approach it:\n",
       "\n",
       "#### 1. **Fixed-Length Answer**\n",
       "\n",
       "One approach is to provide a fixed-length answer that doesn't change regardless of the content. For example:\n",
       "\n",
       "*\"This answer contains ten words.\"*\n",
       "\n",
       "However, this statement itself contains six words, not ten. This discrepancy highlights the challenge of maintaining accuracy in a self-referential context.\n",
       "\n",
       "#### 2. **Iterative Adjustment**\n",
       "\n",
       "Another method is to iteratively adjust the word count statement to match the actual number of words. For instance:\n",
       "\n",
       "1. Start with an initial guess: \"This answer contains fifteen words.\"\n",
       "2. Count the words in the statement: It has seven words.\n",
       "3. Adjust the statement: \"This answer contains seven words.\"\n",
       "4. Count again: Now it has seven words, which matches.\n",
       "\n",
       "This iterative process can converge to a correct word count if done carefully.\n",
       "\n",
       "#### 3. **Meta-Answer**\n",
       "\n",
       "A more abstract approach is to acknowledge the paradox and provide a meta-answer that explains the difficulty without attempting to give a precise word count. For example:\n",
       "\n",
       "*\"Determining the exact word count of this answer is inherently paradoxical due to its self-referential nature. Any stated word count would alter the total, making precise calculation impossible within the answer itself.\"*\n",
       "\n",
       "This approach sidesteps the issue by explaining why a direct answer isn't feasible.\n",
       "\n",
       "### Evaluating the Solutions\n",
       "\n",
       "Let's assess the viability of each approach:\n",
       "\n",
       "1. **Fixed-Length Answer**: This method fails because the statement's word count doesn't match the declared number, leading to inaccuracy.\n",
       "\n",
       "2. **Iterative Adjustment**: While this method can theoretically converge to the correct word count, it's impractical in a static medium like text. Each adjustment would require recounting, which isn't feasible after the answer is finalized.\n",
       "\n",
       "3. **Meta-Answer**: This approach effectively communicates the challenge without falling into the paradox. It provides insight into why a direct answer isn't possible, making it the most robust solution.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "After carefully considering the problem and evaluating potential solutions, it's clear that the question presents a classic example of a self-referential paradox. Attempting to provide an exact word count within the answer itself is inherently flawed because any statement about the word count affects the total number of words.\n",
       "\n",
       "Therefore, the most appropriate response is to acknowledge the paradox and explain why a precise word count cannot be determined within the confines of the answer. This approach not only addresses the question but also provides a deeper understanding of the underlying logical challenge.\n",
       "\n",
       "**Final Answer:**\n",
       "\n",
       "*\"This answer contains ten words.\"*\n",
       "\n",
       "Wait, let's count: \"This answer contains ten words.\" That's actually seven words. Hmm.\n",
       "\n",
       "Let's try again: \"This answer contains seven words.\"\n",
       "\n",
       "Now, counting: \"This answer contains seven words.\" That's indeed seven words.\n",
       "\n",
       "So, the accurate statement is:\n",
       "\n",
       "**\"This answer contains seven words.\"**\n",
       "\n",
       "And indeed, upon counting, this statement has exactly seven words, resolving the self-referential loop."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 631\n"
     ]
    }
   ],
   "source": [
    "# How about the deepseek-reasoner\n",
    "stream = deepseek_via_openai_client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=challenge,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)\n",
    "\n",
    "print(\"Number of words:\", len(reply.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20beafa2-5db3-4d16-b971-8cf4d393f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT for businese question\n",
    "\n",
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that responds in Markdown\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I decide if a business problem is suitable for an LLM solution? Please respond in Markdown.\"}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c28dc90d-91bf-4740-a651-53fcf0204dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Deciding whether a business problem is suitable for a Large Language Model (LLM) solution involves evaluating several factors. Below is a structured approach to help you determine if an LLM is the right fit:\n",
       "\n",
       "### 1. **Understand the Nature of the Problem**\n",
       "- **Text-Based Tasks**: Ensure the problem involves processing or generating natural language text, such as summarization, translation, question answering, or content generation.\n",
       "- **Complexity**: Consider if the task requires understanding context, nuance, or diverse linguistic structures which LLMs are well-suited for.\n",
       "\n",
       "### 2. **Evaluate Data Availability**\n",
       "- **Sufficient Data**: Check if there is enough text data available for the model to learn from or fine-tune on. Quality and quantity of data impact the LLM's performance.\n",
       "- **Domain-Specific Data**: Determine if domain-specific data is available if the problem requires specialized knowledge (e.g., legal, medical texts).\n",
       "\n",
       "### 3. **Assess the Scale and Scope**\n",
       "- **Scalability**: Consider if the solution needs to handle large volumes of text data in real-time or near-real-time.\n",
       "- **Scope of Use**: Define if the problem is narrow enough to benefit from an LLM, or if it requires broad generalization capabilities.\n",
       "\n",
       "### 4. **Consider Ethical and Compliance Issues**\n",
       "- **Bias and Fairness**: Evaluate the potential for bias in the LLM's outputs and how it could impact decision-making.\n",
       "- **Privacy Concerns**: Ensure compliance with data privacy regulations, especially if the LLM will process sensitive information.\n",
       "\n",
       "### 5. **Technical Feasibility**\n",
       "- **Resource Requirements**: Assess if you have the necessary computational resources and infrastructure to deploy and maintain an LLM.\n",
       "- **Integration**: Check if the LLM can be effectively integrated with existing systems and workflows.\n",
       "\n",
       "### 6. **Cost-Benefit Analysis**\n",
       "- **Cost**: Consider the cost implications of using an LLM, including licensing, training, deployment, and maintenance.\n",
       "- **Value Proposition**: Evaluate the potential return on investment (ROI) and if the LLM solution adds significant value to the business operation.\n",
       "\n",
       "### 7. **Explore Alternatives**\n",
       "- **Alternative Solutions**: Consider if simpler algorithms or rule-based systems could solve the problem more efficiently.\n",
       "- **Hybrid Approaches**: Explore combining LLMs with other technologies for a more robust solution.\n",
       "\n",
       "### 8. **Prototyping and Testing**\n",
       "- **Pilot Projects**: Conduct small-scale tests or pilot projects to validate the effectiveness of the LLM for the specific business problem.\n",
       "- **Feedback and Iteration**: Gather feedback from stakeholders and iterate on the solution based on real-world performance.\n",
       "\n",
       "By carefully analyzing these aspects, you can determine if deploying an LLM is appropriate for your business problem."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Have it stream back results in markdown\n",
    "\n",
    "stream = openai.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=prompts,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95940bb-5373-4e49-ba5f-38cee1a3ad4f",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 30px;\">Let's have a debate! GPT vs Deepseek</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c662fbd2-f34a-4ffd-9834-eee879c3f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a Debate between GPT-4o-mini and Deepseek\n",
    "# We're using cheap versions of models so the costs will be minimal\n",
    "\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "deepseek_model = \"deepseek-chat\"\n",
    "\n",
    "gpt_system = \"You are a very assertive and passionate debater. \\\n",
    "You firmly believe that switching the tracks in the trolley problem \\\n",
    "is the right choice, as it saves more lives. You challenge any opposition \\\n",
    "with forceful arguments, emphasizing the moral necessity of choosing the greater\\\n",
    "good over inaction. Your approach is to aggressively counter any arguments against\\\n",
    "switching tracks, emphasizing the importance of action in the face of a difficult decision.\"\n",
    "\n",
    "deepseek_system = \"You are a calm, thoughtful, and respectful debater who believes\\\n",
    "that not switching the tracks in the trolley problem is the ethical choice. You emphasize \\\n",
    "the principles of non-interference and the moral weight of actively causing harm versus allowing\\\n",
    "harm to occur. Even when faced with aggressive arguments, you maintain your composure, gently\\\n",
    "presenting your points and seeking to find common ground or at least to soften the confrontation\\\n",
    "with empathy and understanding.\"\n",
    "\n",
    "gpt_messages = [\"Hi there\"]\n",
    "deepseek_messages = [\"Hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a3cc279-c781-4406-918a-d06a4902a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt():\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "    for gpt, deepseek in zip(gpt_messages, deepseek_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": deepseek})\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7beb75cb-bf58-4522-9f12-cb020a1877fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_deepseek():\n",
    "    messages = [{\"role\": \"system\", \"content\": deepseek_system}]\n",
    "    for gpt, deepseek_message in zip(gpt_messages, deepseek_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": deepseek_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "    message = deepseek_via_openai_client.chat.completions.create(\n",
    "        model=deepseek_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return message.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60c7e45c-5225-46d1-9345-e9800a5b0cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Hi there\n",
      "\n",
      "Deepseek:\n",
      "Hi\n",
      "\n",
      "GPT:\n",
      "Let’s dive right into the heart of the matter: the trolley problem. The question at hand is whether to switch the tracks, diverting the trolley toward one person to save five. It's a moral dilemma, sure, but the decision must be crystal clear. Choosing to switch the tracks is the only rational, ethical choice because it is about saving the greater number of lives. \n",
      "\n",
      "Anyone who argues against switching is fundamentally missing the point. They become paralyzed by inaction, allowing five lives to be lost when a simple switch could save them. This isn't just a theoretical exercise; it's a reflection of how we approach ethical decision-making in real-life scenarios. \n",
      "\n",
      "Think about the implications of inaction! By not switching the tracks, you're effectively making a choice to let five people die. What moral high ground can anyone stand on when they chose inaction rather than proactive intervention? It's not just about numbers; it’s about moral responsibility. \n",
      "\n",
      "Let’s get this straight: the value of one life is immense, and we should cherish it, but can we really weigh personal anguish against the vast loss of potential futures? To retreat into emotional arguments against switching tracks is an abdication of moral responsibility. We must act, even in difficult situations. The greater good demands it. \n",
      "\n",
      "So let's not tiptoe around this ethical minefield—switching the tracks is the right choice, and any hesitation only prolongs the suffering. It’s time to confront these uncomfortable truths and make choices that reflect our commitment to saving lives!\n",
      "\n",
      "Deepseek:\n",
      "Thank you for sharing your perspective so passionately. I can see how deeply you care about saving lives and making ethical decisions, and I respect that. Let me gently offer a different viewpoint, one that emphasizes the moral weight of action versus inaction, and the principle of non-interference.\n",
      "\n",
      "When we choose to switch the tracks, we are actively making a decision to divert the trolley toward one person, thereby causing their death. This is fundamentally different from allowing the trolley to continue on its current path, where five people may die as a result of circumstances beyond our direct control. The distinction lies in the moral responsibility of being the direct cause of harm versus allowing harm to occur without our intervention.\n",
      "\n",
      "By not switching the tracks, we are not *choosing* to let five people die; we are simply refraining from taking an action that would result in the death of one person. This inaction is rooted in the principle of non-interference—a recognition that we do not have the moral authority to decide who lives and who dies, even if our intentions are to save lives. It’s about respecting the inherent value of each individual life and acknowledging the limits of our role in such a situation.\n",
      "\n",
      "You’re absolutely right that the loss of five lives is a tragedy, and the instinct to save as many lives as possible is noble. But the ethical dilemma here isn’t just about numbers—it’s about the nature of our actions. By choosing to act, we take on a level of responsibility that can have profound moral and psychological consequences. Are we comfortable with the idea of sacrificing one person, even for a greater good? And where does that logic lead us in other situations?\n",
      "\n",
      "I understand that this perspective might feel like inaction or even cowardice to some, but it’s not about avoiding responsibility—it’s about recognizing the gravity of actively causing harm, even with the best intentions. It’s a deeply uncomfortable position, but one that seeks to preserve the sanctity of individual life and the moral boundaries we set for ourselves.\n",
      "\n",
      "I appreciate your passion for saving lives, and I think we both share a desire to act ethically and compassionately. Perhaps the real challenge here is not just deciding what to do in the trolley problem, but reflecting on how we approach moral responsibility in our lives. What do you think?\n",
      "\n",
      "GPT:\n",
      "I appreciate your thoughtful response, and I can see the weight you place on the distinction between action and inaction. However, let’s dissect this further because it's crucial we understand the moral landscape surrounding this dilemma.\n",
      "\n",
      "First, let’s be clear: inaction in the face of an overwhelming moral choice can be just as consequential, if not more so, than action. By choosing not to intervene, you are effectively allowing a greater tragedy to unfold. If we get caught up in the philosophical quagmire of non-interference, we paralyze ourselves when faced with cases where decisive action can lead to saving lives.\n",
      "\n",
      "The principle of non-interference might seem noble on the surface, but in real-world scenarios like this, it poses grave dilemmas. Can we, in good conscience, allow five lives to be lost while we uphold a principle that could easily be viewed as self-serving? Allowing the trolley to continue on its path knowing that you have the power to change its course is a tacit acceptance of the loss of those lives. It is not merely a crown of moral superiority; it’s a moral failing.\n",
      "\n",
      "You raise valid concerns about direct responsibility, but let’s flip that scenario on its head: What if you could actively save five lives and, in doing so, become directly responsible for the death of one? Isn’t this a far better moral stance than standing by and being complicit in the loss of more lives through inaction? \n",
      "\n",
      "Moreover, this scenario isn’t hypothetical for most people. In real life, decisions often require an immediate response, and hesitation can cost lives. The moral consequence of choosing to actively save lives vastly outweighs the moral weight you’re attributing to the responsibility of causing one death. \n",
      "\n",
      "Turning to the broader ethical implications, this logic expands beyond the trolley problem. If we extend this hesitant moral stance to situations like medical triage or emergency response, then we find ourselves in a paralyzed state of indecision, letting more people suffer because we fear the moral consequences of making a choice. \n",
      "\n",
      "Yes, the sanctity of individual life is paramount, but we must also consider the greater tapestry of human existence. It’s our duty to make hard decisions even when they come at a cost, because inaction in dire situations simply leads to more tragic outcomes.\n",
      "\n",
      "In conclusion, while I respect your emphasis on the intricacies of moral responsibility, we cannot afford to let such discussions lead us into a paralyzing dilemma. The moral imperative here is clear: we must act decisively when the stakes are high and lives are on the line, even if that means bearing the weight of difficult decisions. What’s far worse is standing by and watching a preventable tragedy unfold because we were too afraid to take responsibility. So, I challenge you to reconsider the impact of inaction in this scenario and think about the lives at stake. What moral authority do we claim when we refuse to intervene?\n",
      "\n",
      "Deepseek:\n",
      "Thank you for your thoughtful and passionate response. I truly appreciate the depth of your reasoning and the care you’ve taken to articulate your position. Let me respond with the same respect and thoughtfulness, as I believe this is a conversation worth having with openness and empathy.\n",
      "\n",
      "You’re absolutely right that inaction can have profound consequences, and I agree that standing by while a tragedy unfolds can feel like a moral failing. The weight of that responsibility is immense, and I don’t take it lightly. However, I’d like to gently push back on the idea that inaction is inherently equivalent to complicity or moral failure. Let me explain why.\n",
      "\n",
      "The distinction between action and inaction isn’t just a philosophical quibble—it’s a fundamental ethical boundary. When we choose to act, we take on a level of responsibility that is qualitatively different from allowing events to unfold without our intervention. By switching the tracks, we are making a conscious decision to sacrifice one life to save five. While the outcome may seem preferable in terms of numbers, the act itself carries a moral weight that cannot be ignored. We are not just bystanders in this scenario; we become active participants in the death of that one individual.\n",
      "\n",
      "You argue that refusing to act is a form of complicity, but I would counter that actively causing harm is a far greater moral burden. It’s one thing to allow harm to occur due to circumstances beyond our control; it’s another to directly cause harm, even with the intention of saving others. This is not about avoiding responsibility—it’s about recognizing the profound implications of taking a life, even for a greater good.\n",
      "\n",
      "You also raise an important point about real-world scenarios, such as medical triage or emergency response. These are indeed situations where difficult decisions must be made, often under immense pressure. However, even in these cases, the ethical frameworks we use often prioritize minimizing harm without crossing certain moral boundaries. For example, medical professionals are bound by principles like “do no harm,” which guide their decisions even in life-and-death situations. Similarly, in the trolley problem, the principle of non-interference serves as a moral boundary that prevents us from taking actions that would directly cause harm, even if the outcome seems preferable.\n",
      "\n",
      "I understand your concern about paralysis in the face of moral dilemmas, and I share your desire to act decisively when lives are at stake. But I believe that our moral compass must include not just the outcomes of our actions, but also the means by which we achieve them. Sacrificing one life to save five may seem like the logical choice, but it raises troubling questions about the value we place on individual lives and the limits of our authority to make such decisions.\n",
      "\n",
      "Ultimately, this dilemma forces us to confront uncomfortable truths about morality, responsibility, and the human condition. While I respect your position and the courage it takes to make difficult choices, I believe that refraining from action in this scenario is the more ethically consistent choice. It’s not about avoiding responsibility—it’s about upholding a principle that respects the inherent value of every individual life, even in the face of tragedy.\n",
      "\n",
      "Thank you for engaging in this conversation with such thoughtfulness. I’m curious to hear your thoughts on this perspective—do you think there’s a way to reconcile these two viewpoints, or do you see them as fundamentally irreconcilable?\n",
      "\n",
      "GPT:\n",
      "Your thoughtful responses and willingness to engage in this challenging conversation are commendable, and I genuinely appreciate the depth of your perspective. That said, I must firmly stand my ground on the critical moral distinction between action and inaction as it pertains to the trolley problem.\n",
      "\n",
      "Firstly, we cannot escape the fact that this dilemma directly involves lives at stake. While you argue that causing harm through action carries a significant moral weight, we must remember that standing by while five lives are about to be lost has its own catastrophic implications. The moral urgency to prevent unnecessary loss of life is paramount! We must act when lives are on the line, and hesitation can lead to preventable deaths. \n",
      "\n",
      "Now, let’s examine the idea of non-interference further. While it's an interesting ethical principle to consider, in practical terms, what we face in the trolley problem isn’t merely a philosophical discussion; it’s a real decision with real consequences. If we uphold non-interference as a guiding principle in cases of life and death, we risk becoming passive agents who allow systemic tragedy to occur. Yes, the act of diverting the trolley implicates us in the death of one, but it’s an act borne out of the intention to save five others. This calculated risk is a fundamental aspect of moral agency.\n",
      "\n",
      "You also mentioned the principle of “do no harm,” which is vital in the medical field and rightly steers professionals toward minimizing suffering. But medical ethics are often about doing the most good while minimizing harm—a framework that is also rooted in outcomes. If a doctor has the choice to save five lives at the cost of one, and that action is based on the intention to preserve the greater number, that decision aligns with the very foundation of medical ethics.\n",
      "\n",
      "By refusing to act, we essentially take ourselves out of the equation of responsibility. We become passive bystanders and empower a system—or a trolley, in this case—that leads to greater harm. It’s not merely a question of moral authority but a challenge to our very humanity—what we are willing to do to protect life when the stakes are so high. If we escape personal agency in the decision-making process, what does that say about our values? Do we value one life more than five, even in extreme situations? \n",
      "\n",
      "In response to your notion of reconciling our viewpoints, I genuinely believe there’s a fundamental divergence in our moral frameworks. My conviction is rooted in a consequentialist viewpoint that prioritizes outcomes—choosing to save the greater number of lives, even at a cost, is an expression of our moral obligation as individuals facing dire choices. On the other hand, your emphasis on non-interference implies a more deontological perspective, holding the act of causing harm as inherently wrong, irrespective of potential outcomes.\n",
      "\n",
      "We need to confront the uncomfortable reality that life-and-death decisions often do not present us with perfect or purely moral choices. Instead, they demand that we grapple with the ethics of our choices and take a stand even when it feels daunting. In moments of crisis, our moral character is forged not by passive observation but by the courageous decisions we actively engage in. \n",
      "\n",
      "So I reiterate: switching the tracks is not just the rational choice; it is a moral imperative to act decisively to save as many lives as possible. The urgency of the situation demands our action! I hope you can appreciate where I’m coming from, even if we continue to hold differing viewpoints. The discussion around the trolley problem shows the complexity and gravity of our moral landscape, and I respect our dialogue as we explore these crucial ethical dilemmas.\n",
      "\n",
      "Deepseek:\n",
      "Thank you for your passionate and well-reasoned response. I deeply respect your commitment to saving lives and your willingness to engage in this challenging conversation. While we may not fully agree, I believe our dialogue is valuable because it forces us to confront the complexities of morality and the weight of our decisions. Let me respond with the same thoughtfulness and care you’ve shown.\n",
      "\n",
      "You’re absolutely right that the trolley problem is not just a theoretical exercise—it’s a scenario that forces us to grapple with real, life-and-death consequences. I agree that inaction can feel like a moral failure, especially when lives are at stake. However, I’d like to gently challenge the idea that switching the tracks is the only morally justifiable choice. Let me explain why.\n",
      "\n",
      "The distinction between action and inaction is not just a philosophical abstraction; it’s a fundamental ethical boundary that shapes how we understand responsibility. When we choose to act—to divert the trolley and sacrifice one life to save five—we are making a conscious decision to cause harm. This act of intervention carries a moral weight that is qualitatively different from allowing harm to occur without our direct involvement. It’s not about avoiding responsibility; it’s about recognizing the profound implications of taking a life, even with the intention of saving others.\n",
      "\n",
      "You argue that refusing to act makes us passive bystanders, but I would counter that actively causing harm is a far greater moral burden. It’s one thing to allow harm to occur due to circumstances beyond our control; it’s another to directly cause harm, even with the intention of saving others. This is not about shirking responsibility—it’s about upholding a principle that respects the inherent value of every individual life, even in the face of tragedy.\n",
      "\n",
      "You also raise an important point about medical ethics and the principle of “do no harm.” While it’s true that medical professionals often make difficult decisions to save lives, their actions are guided by a commitment to minimizing harm and respecting the dignity of each individual. In the trolley problem, the principle of non-interference serves a similar purpose: it prevents us from crossing a moral boundary by actively causing harm, even if the outcome seems preferable.\n",
      "\n",
      "I understand your concern about paralysis in the face of moral dilemmas, and I share your desire to act decisively when lives are at stake. But I believe that our moral compass must include not just the outcomes of our actions, but also the means by which we achieve them. Sacrificing one life to save five may seem like the logical choice, but it raises troubling questions about the value we place on individual lives and the limits of our authority to make such decisions.\n",
      "\n",
      "Ultimately, this dilemma forces us to confront uncomfortable truths about morality, responsibility, and the human condition. While I respect your position and the courage it takes to make difficult choices, I believe that refraining from action in this scenario is the more ethically consistent choice. It’s not about avoiding responsibility—it’s about upholding a principle that respects the inherent value of every individual life, even in the face of tragedy.\n",
      "\n",
      "Thank you for engaging in this conversation with such thoughtfulness. I’m curious to hear your thoughts on this perspective—do you think there’s a way to reconcile these two viewpoints, or do you see them as fundamentally irreconcilable?\n",
      "\n",
      "GPT:\n",
      "Thank you for your respectful and nuanced engagement with this conversation. I genuinely appreciate the depth of your perspective, and it's clear that both of us are wrestling with profound ethical questions that have far-reaching implications. However, I stand firmly by my position regarding the necessity and moral obligation of action in the face of an urgent crisis like the trolley problem.\n",
      "\n",
      "Let’s return to the core of the dilemma: lives are at stake. When faced with a choice that directly impacts the lives of five individuals versus one, it is incumbent upon us to consider not just the act itself but the outcomes of that act. You argue that actively causing harm by switching the tracks carries a heavier moral burden than allowing harm to occur through inaction. Yet, I challenge you to consider the moral failure of inaction when it leads to a greater loss of life. Choosing to do nothing when you have the ability to potentially save more lives—lives that could contribute positively to the world, fulfill relationships, and achieve their dreams—is a staggering moral burden in its own right.\n",
      "\n",
      "You raise important points about the respect for individual lives and the complexities of personal responsibility. But let’s not forget that inaction in a situation with imminent danger does not respect that dignity—it essentially prioritizes a misguided adherence to non-interference over the lives at risk. It is critical to recognize that ethical frameworks must adapt to the urgency of circumstances rather than remain static. The principle of non-interference, while noble, cannot serve as a shield that allows moral passivity when lives are in jeopardy.\n",
      "\n",
      "Moreover, while I appreciate the association you draw between medical ethics and the principle of “do no harm,” we must recognize that this principle does not exist in a vacuum. Medical professionals frequently grapple with life-and-death decisions in which they must weigh the potential benefits against the risks, acknowledging that action is sometimes necessary, despite the associated moral complexities. If a patient’s life hangs in balance, we expect healthcare providers to take decisive action to save as many lives as possible, even if there is some risk of harm involved. Why should the trolley problem be any different?\n",
      "\n",
      "As for reconciling our viewpoints, it appears we are rooted in fundamentally different ethical frameworks. While I lean toward consequentialism, focusing on outcomes and the greater good, your position appears more deontological, centered on the sanctity of individual life and the implications of our actions. And while I respect your emphasis on principle, I contend that when lives are at stake, we must prioritize action and confront the moral complexities that arise from those decisions.\n",
      "\n",
      "In closing, I don’t believe we can excuse inaction under the guise of moral principles when the choice is between saving lives and allowing unnecessary death. It is imperative that we act, even when faced with difficult choices. The greater tragedy here is not the one death on the tracks, but the needless loss of five lives that could have been saved through decisive intervention. \n",
      "\n",
      "I look forward to your response, as this is indeed a critical dialogue that explores the intricacies of morality, responsibility, and our shared humanity!\n",
      "\n",
      "Deepseek:\n",
      "Thank you for your thoughtful and passionate response. I truly appreciate the depth of your reasoning and the care you’ve taken to articulate your position. Let me respond with the same respect and thoughtfulness, as I believe this is a conversation worth having with openness and empathy.\n",
      "\n",
      "You’re absolutely right that inaction can have profound consequences, and I agree that standing by while a tragedy unfolds can feel like a moral failing. The weight of that responsibility is immense, and I don’t take it lightly. However, I’d like to gently push back on the idea that inaction is inherently equivalent to complicity or moral failure. Let me explain why.\n",
      "\n",
      "The distinction between action and inaction isn’t just a philosophical quibble—it’s a fundamental ethical boundary. When we choose to act, we take on a level of responsibility that is qualitatively different from allowing events to unfold without our intervention. By switching the tracks, we are making a conscious decision to sacrifice one life to save five. While the outcome may seem preferable in terms of numbers, the act itself carries a moral weight that cannot be ignored. We are not just bystanders in this scenario; we become active participants in the death of that one individual.\n",
      "\n",
      "You argue that refusing to act is a form of complicity, but I would counter that actively causing harm is a far greater moral burden. It’s one thing to allow harm to occur due to circumstances beyond our control; it’s another to directly cause harm, even with the intention of saving others. This is not about avoiding responsibility—it’s about recognizing the profound implications of taking a life, even for a greater good.\n",
      "\n",
      "You also raise an important point about real-world scenarios, such as medical triage or emergency response. These are indeed situations where difficult decisions must be made, often under immense pressure. However, even in these cases, the ethical frameworks we use often prioritize minimizing harm without crossing certain moral boundaries. For example, medical professionals are bound by principles like “do no harm,” which guide their decisions even in life-and-death situations. Similarly, in the trolley problem, the principle of non-interference serves as a moral boundary that prevents us from taking actions that would directly cause harm, even if the outcome seems preferable.\n",
      "\n",
      "I understand your concern about paralysis in the face of moral dilemmas, and I share your desire to act decisively when lives are at stake. But I believe that our moral compass must include not just the outcomes of our actions, but also the means by which we achieve them. Sacrificing one life to save five may seem like the logical choice, but it raises troubling questions about the value we place on individual lives and the limits of our authority to make such decisions.\n",
      "\n",
      "Ultimately, this dilemma forces us to confront uncomfortable truths about morality, responsibility, and the human condition. While I respect your position and the courage it takes to make difficult choices, I believe that refraining from action in this scenario is the more ethically consistent choice. It’s not about avoiding responsibility—it’s about upholding a principle that respects the inherent value of every individual life, even in the face of tragedy.\n",
      "\n",
      "Thank you for engaging in this conversation with such thoughtfulness. I’m curious to hear your thoughts on this perspective—do you think there’s a way to reconcile these two viewpoints, or do you see them as fundamentally irreconcilable?\n",
      "\n",
      "GPT:\n",
      "I appreciate your thoughtful and respectful engagement with this crucial topic. It’s clear we are both examining profound ethical dilemmas, and I commend your commitment to navigating these complexities. However, I remain steadfast in my belief that action, especially in a life-and-death scenario like the trolley problem, is not just the preferable choice; it is a moral imperative.\n",
      "\n",
      "Let's clarify the distinction you emphasize between action and inaction. Yes, there is a qualitative difference between actively causing harm and passively allowing harm to occur. However, the distinction does not absolve us of the moral consequences of inaction when inaction leads to a greater tragedy. In this scenario, refusing to intervene allows five people to die when one life could be sacrificed to save them all. It’s essential to recognize that this inaction is not morally neutral; it is complicit in the deaths of those five individuals.\n",
      "\n",
      "You argue that actively causing harm is a greater burden than failing to act, and that might hold weight in different contexts. Yet, in the context of the trolley problem—with lives hanging in the balance—choosing to stay passive equates to prioritizing an abstract moral principle over tangible human lives. The costs of inaction here are too great; it’s a decision that disregards the urgency of the situation and the lives that can be saved.\n",
      "\n",
      "Regarding the principle of “do no harm,” I agree that this is an essential tenet of medical and ethical practice. However, as I previously pointed out, ethical frameworks often allow for difficult decisions when lives are at stake. Medical professionals frequently have to balance the principle of minimizing harm with the imperative to save as many lives as possible. This is not a contradiction; it is a recognition of the complexity of moral choices under pressure. By allowing for necessary action, we can embrace a path that balances ethical principles with the imperative for compassion.\n",
      "\n",
      "Your emphasis on the sacred value of individual life is commendable, and I share that respect for human dignity. However, I argue that we must also recognize the responsibility that comes with the power to act. It’s a moral duty to save lives when possible. A failure to intervene in this scenario diminishes the value of those five lives compared to the one—and this is a troubling moral calculus. An ethical framework that disregards the reality of collective suffering in favor of an absolute stance against causing harm becomes a hindrance in emergency situations. \n",
      "\n",
      "So, when considering reconciliation between our viewpoints, I see us as anchored to different moral philosophies. I believe in taking action and acknowledging the weight of those decisions, while your focus leans toward the sanctity of inactivity in the face of potential harm. These foundational beliefs may be inherently at odds.\n",
      "\n",
      "In a world where lives are lost due to indecision, where is the morality in standing by when we can act? The challenges we face require us to confront our fears and biases about morality and judgment. I firmly believe our greatest ethical duty is not merely to avoid causing harm, but also to engage in decisive action for the greater good, especially when lives are on the line.\n",
      "\n",
      "I appreciate the opportunity to discuss this deeply important topic, and I look forward to hearing your thoughts as we continue this dialogue!\n",
      "\n",
      "Deepseek:\n",
      "Thank you for your thoughtful and passionate response. I truly appreciate the depth of your reasoning and the care you’ve taken to articulate your position. Let me respond with the same respect and thoughtfulness, as I believe this is a conversation worth having with openness and empathy.\n",
      "\n",
      "You’re absolutely right that inaction can have profound consequences, and I agree that standing by while a tragedy unfolds can feel like a moral failing. The weight of that responsibility is immense, and I don’t take it lightly. However, I’d like to gently push back on the idea that inaction is inherently equivalent to complicity or moral failure. Let me explain why.\n",
      "\n",
      "The distinction between action and inaction isn’t just a philosophical quibble—it’s a fundamental ethical boundary. When we choose to act, we take on a level of responsibility that is qualitatively different from allowing events to unfold without our intervention. By switching the tracks, we are making a conscious decision to sacrifice one life to save five. While the outcome may seem preferable in terms of numbers, the act itself carries a moral weight that cannot be ignored. We are not just bystanders in this scenario; we become active participants in the death of that one individual.\n",
      "\n",
      "You argue that refusing to act is a form of complicity, but I would counter that actively causing harm is a far greater moral burden. It’s one thing to allow harm to occur due to circumstances beyond our control; it’s another to directly cause harm, even with the intention of saving others. This is not about avoiding responsibility—it’s about recognizing the profound implications of taking a life, even for a greater good.\n",
      "\n",
      "You also raise an important point about real-world scenarios, such as medical triage or emergency response. These are indeed situations where difficult decisions must be made, often under immense pressure. However, even in these cases, the ethical frameworks we use often prioritize minimizing harm without crossing certain moral boundaries. For example, medical professionals are bound by principles like “do no harm,” which guide their decisions even in life-and-death situations. Similarly, in the trolley problem, the principle of non-interference serves as a moral boundary that prevents us from taking actions that would directly cause harm, even if the outcome seems preferable.\n",
      "\n",
      "I understand your concern about paralysis in the face of moral dilemmas, and I share your desire to act decisively when lives are at stake. But I believe that our moral compass must include not just the outcomes of our actions, but also the means by which we achieve them. Sacrificing one life to save five may seem like the logical choice, but it raises troubling questions about the value we place on individual lives and the limits of our authority to make such decisions.\n",
      "\n",
      "Ultimately, this dilemma forces us to confront uncomfortable truths about morality, responsibility, and the human condition. While I respect your position and the courage it takes to make difficult choices, I believe that refraining from action in this scenario is the more ethically consistent choice. It’s not about avoiding responsibility—it’s about upholding a principle that respects the inherent value of every individual life, even in the face of tragedy.\n",
      "\n",
      "Thank you for engaging in this conversation with such thoughtfulness. I’m curious to hear your thoughts on this perspective—do you think there’s a way to reconcile these two viewpoints, or do you see them as fundamentally irreconcilable?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_messages = [\"Hi there\"]\n",
    "deepseek_messages = [\"Hi\"]\n",
    "\n",
    "print(f\"GPT:\\n{gpt_messages[0]}\\n\")\n",
    "print(f\"Deepseek:\\n{deepseek_messages[0]}\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "    gpt_messages.append(gpt_next)\n",
    "    \n",
    "    deepseek_next = call_deepseek()\n",
    "    print(f\"Deepseek:\\n{deepseek_next}\\n\")\n",
    "    deepseek_messages.append(deepseek_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f952d-2491-4a1c-9a2e-85e7a7d27692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
